{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a16487-966b-4ac6-9cb8-a38025a65b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "# https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "#### PREPROCESS.PY\n",
    "#### PREPROCESS.PY\n",
    "#### PREPROCESS.PY\n",
    "#### PREPROCESS.PY\n",
    "#### PREPROCESS.PY\n",
    "#### NER ACCORDING to SCPAY MANUAL 3\n",
    "#### NER ACCORDING to SCPAY MANUAL 3\n",
    "#### NER ACCORDING to SCPAY MANUAL 3\n",
    "#### NER ACCORDING to SCPAY MANUAL 3\n",
    "#### NER ACCORDING to SCPAY MANUAL 3\n",
    "# ===> https://spacy.io/usage/training\n",
    "# ===> https://spacy.io/usage/training\n",
    "# ===> https://spacy.io/usage/training\n",
    "# ===> https://spacy.io/usage/training\n",
    "# ===> https://spacy.io/usage/training\n",
    "# ===> https://spacy.io/usage/training\n",
    "# ===> https://spacy.io/usage/training\n",
    "\n",
    "#import spacy\n",
    "#from spacy.tokens import DocBin\n",
    "#from spacy.training import offsets_to_biluo_tags\n",
    "#nlp = spacy.blank(\"en\")\n",
    "\n",
    "training_data = [\n",
    "            (\"Walmart is a leading e-commerce company.\", [(0, 7, \"ORG\")]),\n",
    "            (\"I reached Chennai yesterday.\", [(18, 28, \"GPE\")]),\n",
    "            (\"I recently ordered a book from Amazon.\", [(31,38, \"ORG\")]),\n",
    "            (\"I was driving a BMW.\", [(16,20, \"PRODUCT\")]),\n",
    "            (\"I ordered this from ShopClues.\", [(20,30, \"ORG\")]),\n",
    "            (\"Fridge can be ordered in Amazon.\", [(0,6, \"PRODUCT\")]),\n",
    "            (\"I bought a new Washer.\", [(15,21, \"PRODUCT\")]),\n",
    "            (\"I bought a old table.\", [(15,20, \"PRODUCT\")]),\n",
    "            (\"I bought a fancy dress.\", [(17,23, \"PRODUCT\")]),\n",
    "            (\"I rented a camera.\", [(11,18, \"PRODUCT\")]),\n",
    "            (\"I rented a tent for our trip.\", [(11,15, \"PRODUCT\")]),\n",
    "            (\"I rented a screwdriver from our neighbour.\", [(11,22, \"PRODUCT\")]),\n",
    "            (\"I repaired my computer.\", [(14,23, \"PRODUCT\")]),\n",
    "            (\"I got my clock fixed.\", [(9,14, \"PRODUCT\")]),\n",
    "            (\"Flipkart started it's journey from zero.\", [(0,8, \"ORG\")]),\n",
    "            (\"I recently ordered from Max.\", [(24,28, \"ORG\")]),\n",
    "            (\"Flipkart is recognized as leader in market.\",[(0,8, \"ORG\")]),\n",
    "            (\"I recently ordered from Swiggy.\", [(24,31, \"ORG\")]),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e81753-a3d9-494d-aab4-47084811a899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Walmart] ['U-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[yesterday.] ['O', 'O', 'O', 'B-GPE', 'L-GPE']\n",
      "[Amazon.] ['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'L-ORG']\n",
      "[BMW.] ['O', 'O', 'O', 'O', 'B-PRODUCT', 'L-PRODUCT']\n",
      "[ShopClues.] ['O', 'O', 'O', 'O', 'B-ORG', 'L-ORG']\n",
      "[Fridge] ['U-PRODUCT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[Washer] ['O', 'O', 'O', 'O', 'U-PRODUCT', 'O']\n",
      "[table] ['O', 'O', 'O', 'O', 'U-PRODUCT', 'O']\n",
      "[dress.] ['O', 'O', 'O', 'O', 'B-PRODUCT', 'L-PRODUCT']\n",
      "[camera.] ['O', 'O', 'O', 'B-PRODUCT', 'L-PRODUCT']\n",
      "[tent] ['O', 'O', 'O', 'U-PRODUCT', 'O', 'O', 'O', 'O']\n",
      "[screwdriver] ['O', 'O', 'O', 'U-PRODUCT', 'O', 'O', 'O', 'O']\n",
      "[computer.] ['O', 'O', 'O', 'B-PRODUCT', 'L-PRODUCT']\n",
      "[clock] ['O', 'O', 'O', 'U-PRODUCT', 'O', 'O']\n",
      "[Flipkart] ['U-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[Max.] ['O', 'O', 'O', 'O', 'B-ORG', 'L-ORG']\n",
      "[Flipkart] ['U-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[Swiggy.] ['O', 'O', 'O', 'O', 'B-ORG', 'L-ORG']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# the DocBin will store the example documents\n",
    "db = DocBin()\n",
    "for text, annotations in training_data:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label  in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        ents.append(span)\n",
    "    doc.ents = ents\n",
    "    tags = offsets_to_biluo_tags(doc, annotations)\n",
    "    print(ents, tags)\n",
    "    db.add(doc)\n",
    "    #assert doc.has_annotation(\"TAG\")\n",
    "    \n",
    "db.to_disk(\"./train.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3d05bd-2394-40e5-a000-cff5e7bf68e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Generated config template specific for your use case\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config --force ./config.cfg  --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba14d3b-85ff-4823-ac61-6dd279f26074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output_folder\n",
      "[i] Using GPU: 0\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     76.00    0.00    0.00    0.00    0.00\n",
      "200     200         23.56   1419.33  100.00  100.00  100.00    1.00\n",
      "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "[+] Saved pipeline to output directory\n",
      "output_folder\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-14 22:36:23,758] [INFO] Set up nlp object from config\n",
      "[2022-11-14 22:36:23,768] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-11-14 22:36:23,770] [INFO] Created vocabulary\n",
      "[2022-11-14 22:36:23,770] [INFO] Finished initializing nlp object\n",
      "[2022-11-14 22:36:24,863] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy train config.cfg --gpu-id 0 --paths.train train.spacy --paths.dev train.spacy --output output_folder\n",
    "!python -m spacy train --gpu-id 0 config.cfg --paths.train ./train/train.spacy --paths.dev ./dev/dev.spacy --output ./models/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db6f0a5-fc5d-43b7-8726-6ab6c8ef251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart 0\n",
      "is 0\n",
      "a 0\n",
      "leading 0\n",
      "e 0\n",
      "- 0\n",
      "commerce 0\n",
      "company 0\n",
      ". 0\n",
      "I 0\n",
      "reached 0\n",
      "Chennai 0\n",
      "yesterday 0\n",
      ". 0\n",
      "I 0\n",
      "recently 0\n",
      "ordered 0\n",
      "a 0\n",
      "book 0\n",
      "from 0\n",
      "Amazon 0\n",
      ". 0\n",
      "I 0\n",
      "was 0\n",
      "driving 0\n",
      "a 0\n",
      "BMW 0\n",
      ". 0\n",
      "I 0\n",
      "ordered 0\n",
      "this 0\n",
      "from 0\n",
      "ShopClues 0\n",
      ". 0\n",
      "Fridge 0\n",
      "can 0\n",
      "be 0\n",
      "ordered 0\n",
      "in 0\n",
      "Amazon 0\n",
      ". 0\n",
      "I 0\n",
      "bought 0\n",
      "a 0\n",
      "new 0\n",
      "Washer 0\n",
      ". 0\n",
      "I 0\n",
      "bought 0\n",
      "a 0\n",
      "old 0\n",
      "table 0\n",
      ". 0\n",
      "I 0\n",
      "bought 0\n",
      "a 0\n",
      "fancy 0\n",
      "dress 0\n",
      ". 0\n",
      "I 0\n",
      "rented 0\n",
      "a 0\n",
      "camera 0\n",
      ". 0\n",
      "I 0\n",
      "rented 0\n",
      "a 0\n",
      "tent 0\n",
      "for 0\n",
      "our 0\n",
      "trip 0\n",
      ". 0\n",
      "I 0\n",
      "rented 0\n",
      "a 0\n",
      "screwdriver 0\n",
      "from 0\n",
      "our 0\n",
      "neighbour 0\n",
      ". 0\n",
      "I 0\n",
      "repaired 0\n",
      "my 0\n",
      "computer 0\n",
      ". 0\n",
      "I 0\n",
      "got 0\n",
      "my 0\n",
      "clock 0\n",
      "fixed 0\n",
      ". 0\n",
      "Flipkart 0\n",
      "started 0\n",
      "it 0\n",
      "'s 0\n",
      "journey 0\n",
      "from 0\n",
      "zero 0\n",
      ". 0\n",
      "I 0\n",
      "recently 0\n",
      "ordered 0\n",
      "from 0\n",
      "Max 0\n",
      ". 0\n",
      "Flipkart 0\n",
      "is 0\n",
      "recognized 0\n",
      "as 0\n",
      "leader 0\n",
      "in 0\n",
      "market 0\n",
      ". 0\n",
      "I 0\n",
      "recently 0\n",
      "ordered 0\n",
      "from 0\n",
      "Swiggy 0\n",
      ". 0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "db = DocBin().from_disk(\"train.spacy\")\n",
    "for doc in db.get_docs(nlp.vocab):\n",
    "    #assert doc.has_annotation(\"TAG\")\n",
    "    # or just inspect the tags\n",
    "    for token in doc:\n",
    "        print(token.text, token.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2973726-6713-4e2e-a596-46c9b874a372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1be383fb-f7cd-4f68-9883-e9a36ebaf3ed",
   "metadata": {},
   "source": [
    "## WHAT IS config file\n",
    "The config file includes all settings related to training and how to set up the pipeline, but it doesnâ€™t package your pipeline. To create an installable Python package, you can use the spacy package command.\n",
    "\n",
    "https://course.spacy.io/en/chapter4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0aff89b-a9cd-46c6-9c11-a70a3ec86ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Generated config template specific for your use case\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy init fill-config base_config.cfg config.cfg\n",
    "!python -m spacy init config --force ./config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d3134b-56a6-4e40-83b7-9b012622b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] No output directory provided\n",
      "[i] Using CPU\n",
      "[i] To switch to GPU 0, use the option: --gpu-id 0\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     76.00    0.00    0.00    0.00    0.00\n",
      "200     200         12.95   1325.67  100.00  100.00  100.00    1.00\n",
      "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-14 22:45:15,606] [INFO] Set up nlp object from config\n",
      "[2022-11-14 22:45:15,627] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-11-14 22:45:15,627] [INFO] Created vocabulary\n",
      "[2022-11-14 22:45:15,627] [INFO] Finished initializing nlp object\n",
      "[2022-11-14 22:45:15,698] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./train.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57f9edf4-9ea4-414b-80ed-f49b990c2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\click\\core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\click\\core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\click\\core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\typer\\main.py\", line 532, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\\cli\\debug_data.py\", line 75, in debug_data_cli\n",
      "    debug_data(\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\\cli\\debug_data.py\", line 113, in debug_data\n",
      "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\\util.py\", line 606, in resolve_dot_names\n",
      "    result = registry.resolve(config[section])\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\confection\\__init__.py\", line 728, in resolve\n",
      "    resolved, _ = cls._make(\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\confection\\__init__.py\", line 777, in _make\n",
      "    filled, _, resolved = cls._fill(\n",
      "  File \"C:\\Users\\rob\\AppData\\Roaming\\Python\\Python39\\site-packages\\confection\\__init__.py\", line 849, in _fill\n",
      "    getter_result = getter(*args, **kwargs)\n",
      "  File \"C:\\Users\\rob\\anaconda3\\envs\\spacy-GPU-env\\lib\\site-packages\\spacy\\training\\corpus.py\", line 31, in create_docbin_reader\n",
      "    raise ValueError(Errors.E913)\n",
      "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your .cfg file or override it on the CLI?\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy debug data config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d09a8e-cf9d-4724-a161-8c1dad7e4255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: output_folder\n",
      "[i] Using GPU: 0\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner', 'parser']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  LOSS PARSER  ENTS_F  ENTS_P  ENTS_R  DEP_UAS  DEP_LAS  SENTS_F  SCORE \n",
      "---  ------  ------------  --------  -----------  ------  ------  ------  -------  -------  -------  ------\n",
      "  0       0          0.00     76.00         0.00    0.00    0.00    0.00     0.00     0.00     0.00    0.00\n",
      "200     200        779.71   3036.73         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "400     400        683.27    180.41         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "600     600        719.25    102.41         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "800     800        915.43     85.36         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "1000    1000        996.81     62.84         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "1200    1200        597.00     58.36         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "1400    1400       1326.26     47.28         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "1600    1600       2146.54     64.44         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "1800    1800       1540.87     41.72         0.00  100.00  100.00  100.00     0.00     0.00     0.00    0.50\n",
      "[+] Saved pipeline to output directory\n",
      "output_folder\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-14 09:27:55,759] [INFO] Set up nlp object from config\n",
      "[2022-11-14 09:27:55,769] [INFO] Pipeline: ['tok2vec', 'ner', 'parser']\n",
      "[2022-11-14 09:27:55,772] [INFO] Created vocabulary\n",
      "[2022-11-14 09:27:55,772] [INFO] Finished initializing nlp object\n",
      "[2022-11-14 09:27:57,240] [INFO] Initialized pipeline components: ['tok2vec', 'ner', 'parser']\n"
     ]
    }
   ],
   "source": [
    "####  ROSOVE ERROR SEE : https://github.com/explosion/spaCy/discussions/6472\n",
    "!python -m spacy train config.cfg --gpu-id 0 --paths.train train.spacy --paths.dev train.spacy --output output_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ecbbf0-2160-4f8f-a74c-98ddd345996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I was driving a Alto\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1fdf6-ddf7-4f7b-98c6-3785fe1a3995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd0450-d51a-4704-af5e-7963546a9d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
